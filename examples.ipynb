{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import logging, sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kmeans, agnes, dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to evaluate various cluster performance metrics. All except Silhouette compare against the \"correct\" labels, which are gathered from the data generator.\n",
    "You can read more about each below:\n",
    "* [ARI](https://en.wikipedia.org/wiki/Rand_index)\n",
    "* [NMI](https://en.wikipedia.org/wiki/Mutual_information)\n",
    "* [Homogeneity](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure)\n",
    "* [Completeness](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure)\n",
    "* [Silhouette'](https://en.wikipedia.org/wiki/Silhouette_(clustering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(df, labels, i_labels):\n",
    "    m = dict()\n",
    "    m['ARI'] = metrics.adjusted_rand_score(labels, i_labels)\n",
    "    m['NMI'] = metrics.normalized_mutual_info_score(labels,i_labels)\n",
    "    m['Homogeneity'] = metrics.homogeneity_score(labels, i_labels)\n",
    "    m['Completeness'] = metrics.completeness_score(labels, i_labels)\n",
    "    m['Silhouette'] = metrics.silhouette_score(df, i_labels, metric='euclidean')\n",
    "    \n",
    "    return pd.Series(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate the dataset. We'll make a few blobs with some half-moons in there to throw off traditional clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "circles, c_labels = datasets.make_moons(400, True, 0.001, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "circles += 1,1\n",
    "circles *= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blobs, b_labels = datasets.make_blobs(n_samples=600, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blobs -= 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = np.concatenate((circles, blobs))\n",
    "labels = np.concatenate((c_labels, b_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [i[1] for i in merged]\n",
    "x = [i[0] for i in merged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': x, 'y' : y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is what the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.x, df.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLearns kmeans implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = cluster.KMeans(5)\n",
    "k.fit(df)\n",
    "plt.scatter(df.x, df.y, c=k.labels_, cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation['KMeans_ref'] = get_metrics(df, labels, k.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = kmeans.KMeans(5)\n",
    "k2.Fit(df)\n",
    "plt.scatter(df.x, df.y, c=k2.GetLabels(df.shape[0]), cmap='prism') \n",
    "# we pass in df.shape[0] because GetLabels requires a size, in this case the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation['KMeans_impl'] = get_metrics(df, labels, k2.GetLabels(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans also has some extra methods associated with it. You may wish to get the cluster centroids for plotting, or be able to predict a new data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in sk-learn:\n",
    "print('Sk-learn clusters centroids')\n",
    "print(k.cluster_centers_)\n",
    "\n",
    "print()\n",
    "\n",
    "print('C++ cluster centroids')\n",
    "# in c++\n",
    "# first we need to create an empty matrix in the shape of [n_centroids, n_attributes]\n",
    "centroids = np.empty((5, df.shape[1]),)\n",
    "# then we pass it to GetClusters, which populates it\n",
    "k2.GetClusters(centroids)\n",
    "# then we can print the populated array\n",
    "print(centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = np.array(df.iloc[0])\n",
    "\n",
    "print('Tuple: {}'.format(tup))\n",
    "\n",
    "# predicting in sk-learn\n",
    "print('sklearn predicts:')\n",
    "print(k.predict(tup.reshape(1, -1))[0])\n",
    "\n",
    "#predicting in c++\n",
    "print('c++ predicts:')\n",
    "print(k2.Predict(tup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while c++ looks simpler than sklearn, c++ can only predict a single tuple at a time\n",
    "\n",
    "tups = np.array(df.iloc[[0,1,2,3]])\n",
    "print('Tuples:')\n",
    "print(tups)\n",
    "\n",
    "#predicting multipel tuples in sk-learn\n",
    "print('sk-learn predicts:')\n",
    "print(k.predict(tups))\n",
    "\n",
    "#predicting multiple tuples in c++\n",
    "print('c++ predicts:')\n",
    "print([k2.Predict(x) for x in tups])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKlearns Agnes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cluster.AgglomerativeClustering(5, linkage='complete')\n",
    "a.fit(df)\n",
    "plt.scatter(df.x, df.y, c=a.labels_ ,cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation['Agnes_ref'] = get_metrics(df, labels, a.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Agnes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = agnes.Agnes(5, 'complete')\n",
    "a2.Fit(df)\n",
    "plt.scatter(df.x, df.y, c=a2.GetLabels(df.shape[0]), cmap='prism')\n",
    "# we pass in df.shape[0] because GetLabels requires a size, in this case the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation['Agnes_impl'] = get_metrics(df, labels, a2.GetLabels(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Agnes implementation comes with the ability to infer the clusters. While the algorithm is not perfect, it produces acceptable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with bogus values for n_clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = agnes.Agnes(50, 'complete')\n",
    "a2.Fit(df)\n",
    "plt.scatter(df.x, df.y, c=a2.GetLabels(df.shape[0]), cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.x, df.y, c=a2.InferLabels(df.shape[0]), cmap='prism')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agnes also comes with methods to view the cluster hierarchy. `PrintDotGraph()` outputs a block of code suitable for compiling into a graph, such as with graphviz. SK-learn does not currently have functionaly to easily explore the hierarchy structure.\n",
    "\n",
    "We recommend using http://www.webgraphviz.com/ to preview hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting with a subset to reduce graph complexity\n",
    "a2 = agnes.Agnes(5, 'complete')\n",
    "a2.Fit(df.sample(n=100))\n",
    "\n",
    "# PrintDotGraph takes parameters that get inserted\n",
    "# into the beginning of the graph declaration\n",
    "# These should be used for formatting\n",
    "opts = '''splines=False;\n",
    "node [margin=0 fontcolor=blue fontsize=32 width=0.5 shape=circle style=filled];\n",
    "'''\n",
    "print(a2.PrintDotGraph(opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearns dbscan implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cluster.DBSCAN(.6, 6)\n",
    "d.fit(df)\n",
    "plt.scatter(df.x, df.y, c=d.labels_, cmap='prism', label='DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our DBSCAN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = dbscan.DBSCAN(.6,6)\n",
    "dbs.Fit(df)\n",
    "plt.scatter(df.x, df.y, c=dbs.GetLabels(df.shape[0]), cmap='prism', label='DBSCAN')\n",
    "# we pass in df.shape[0] because GetLabels requires a size, in this case the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
